{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n',\n",
       " 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "        [ 4.9,  3. ,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.3,  0.2],\n",
       "        [ 4.6,  3.1,  1.5,  0.2],\n",
       "        [ 5. ,  3.6,  1.4,  0.2],\n",
       "        [ 5.4,  3.9,  1.7,  0.4],\n",
       "        [ 4.6,  3.4,  1.4,  0.3],\n",
       "        [ 5. ,  3.4,  1.5,  0.2],\n",
       "        [ 4.4,  2.9,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5.4,  3.7,  1.5,  0.2],\n",
       "        [ 4.8,  3.4,  1.6,  0.2],\n",
       "        [ 4.8,  3. ,  1.4,  0.1],\n",
       "        [ 4.3,  3. ,  1.1,  0.1],\n",
       "        [ 5.8,  4. ,  1.2,  0.2],\n",
       "        [ 5.7,  4.4,  1.5,  0.4],\n",
       "        [ 5.4,  3.9,  1.3,  0.4],\n",
       "        [ 5.1,  3.5,  1.4,  0.3],\n",
       "        [ 5.7,  3.8,  1.7,  0.3],\n",
       "        [ 5.1,  3.8,  1.5,  0.3],\n",
       "        [ 5.4,  3.4,  1.7,  0.2],\n",
       "        [ 5.1,  3.7,  1.5,  0.4],\n",
       "        [ 4.6,  3.6,  1. ,  0.2],\n",
       "        [ 5.1,  3.3,  1.7,  0.5],\n",
       "        [ 4.8,  3.4,  1.9,  0.2],\n",
       "        [ 5. ,  3. ,  1.6,  0.2],\n",
       "        [ 5. ,  3.4,  1.6,  0.4],\n",
       "        [ 5.2,  3.5,  1.5,  0.2],\n",
       "        [ 5.2,  3.4,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.6,  0.2],\n",
       "        [ 4.8,  3.1,  1.6,  0.2],\n",
       "        [ 5.4,  3.4,  1.5,  0.4],\n",
       "        [ 5.2,  4.1,  1.5,  0.1],\n",
       "        [ 5.5,  4.2,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5. ,  3.2,  1.2,  0.2],\n",
       "        [ 5.5,  3.5,  1.3,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 4.4,  3. ,  1.3,  0.2],\n",
       "        [ 5.1,  3.4,  1.5,  0.2],\n",
       "        [ 5. ,  3.5,  1.3,  0.3],\n",
       "        [ 4.5,  2.3,  1.3,  0.3],\n",
       "        [ 4.4,  3.2,  1.3,  0.2],\n",
       "        [ 5. ,  3.5,  1.6,  0.6],\n",
       "        [ 5.1,  3.8,  1.9,  0.4],\n",
       "        [ 4.8,  3. ,  1.4,  0.3],\n",
       "        [ 5.1,  3.8,  1.6,  0.2],\n",
       "        [ 4.6,  3.2,  1.4,  0.2],\n",
       "        [ 5.3,  3.7,  1.5,  0.2],\n",
       "        [ 5. ,  3.3,  1.4,  0.2],\n",
       "        [ 7. ,  3.2,  4.7,  1.4],\n",
       "        [ 6.4,  3.2,  4.5,  1.5],\n",
       "        [ 6.9,  3.1,  4.9,  1.5],\n",
       "        [ 5.5,  2.3,  4. ,  1.3],\n",
       "        [ 6.5,  2.8,  4.6,  1.5],\n",
       "        [ 5.7,  2.8,  4.5,  1.3],\n",
       "        [ 6.3,  3.3,  4.7,  1.6],\n",
       "        [ 4.9,  2.4,  3.3,  1. ],\n",
       "        [ 6.6,  2.9,  4.6,  1.3],\n",
       "        [ 5.2,  2.7,  3.9,  1.4],\n",
       "        [ 5. ,  2. ,  3.5,  1. ],\n",
       "        [ 5.9,  3. ,  4.2,  1.5],\n",
       "        [ 6. ,  2.2,  4. ,  1. ],\n",
       "        [ 6.1,  2.9,  4.7,  1.4],\n",
       "        [ 5.6,  2.9,  3.6,  1.3],\n",
       "        [ 6.7,  3.1,  4.4,  1.4],\n",
       "        [ 5.6,  3. ,  4.5,  1.5],\n",
       "        [ 5.8,  2.7,  4.1,  1. ],\n",
       "        [ 6.2,  2.2,  4.5,  1.5],\n",
       "        [ 5.6,  2.5,  3.9,  1.1],\n",
       "        [ 5.9,  3.2,  4.8,  1.8],\n",
       "        [ 6.1,  2.8,  4. ,  1.3],\n",
       "        [ 6.3,  2.5,  4.9,  1.5],\n",
       "        [ 6.1,  2.8,  4.7,  1.2],\n",
       "        [ 6.4,  2.9,  4.3,  1.3],\n",
       "        [ 6.6,  3. ,  4.4,  1.4],\n",
       "        [ 6.8,  2.8,  4.8,  1.4],\n",
       "        [ 6.7,  3. ,  5. ,  1.7],\n",
       "        [ 6. ,  2.9,  4.5,  1.5],\n",
       "        [ 5.7,  2.6,  3.5,  1. ],\n",
       "        [ 5.5,  2.4,  3.8,  1.1],\n",
       "        [ 5.5,  2.4,  3.7,  1. ],\n",
       "        [ 5.8,  2.7,  3.9,  1.2],\n",
       "        [ 6. ,  2.7,  5.1,  1.6],\n",
       "        [ 5.4,  3. ,  4.5,  1.5],\n",
       "        [ 6. ,  3.4,  4.5,  1.6],\n",
       "        [ 6.7,  3.1,  4.7,  1.5],\n",
       "        [ 6.3,  2.3,  4.4,  1.3],\n",
       "        [ 5.6,  3. ,  4.1,  1.3],\n",
       "        [ 5.5,  2.5,  4. ,  1.3],\n",
       "        [ 5.5,  2.6,  4.4,  1.2],\n",
       "        [ 6.1,  3. ,  4.6,  1.4],\n",
       "        [ 5.8,  2.6,  4. ,  1.2],\n",
       "        [ 5. ,  2.3,  3.3,  1. ],\n",
       "        [ 5.6,  2.7,  4.2,  1.3],\n",
       "        [ 5.7,  3. ,  4.2,  1.2],\n",
       "        [ 5.7,  2.9,  4.2,  1.3],\n",
       "        [ 6.2,  2.9,  4.3,  1.3],\n",
       "        [ 5.1,  2.5,  3. ,  1.1],\n",
       "        [ 5.7,  2.8,  4.1,  1.3],\n",
       "        [ 6.3,  3.3,  6. ,  2.5],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 7.1,  3. ,  5.9,  2.1],\n",
       "        [ 6.3,  2.9,  5.6,  1.8],\n",
       "        [ 6.5,  3. ,  5.8,  2.2],\n",
       "        [ 7.6,  3. ,  6.6,  2.1],\n",
       "        [ 4.9,  2.5,  4.5,  1.7],\n",
       "        [ 7.3,  2.9,  6.3,  1.8],\n",
       "        [ 6.7,  2.5,  5.8,  1.8],\n",
       "        [ 7.2,  3.6,  6.1,  2.5],\n",
       "        [ 6.5,  3.2,  5.1,  2. ],\n",
       "        [ 6.4,  2.7,  5.3,  1.9],\n",
       "        [ 6.8,  3. ,  5.5,  2.1],\n",
       "        [ 5.7,  2.5,  5. ,  2. ],\n",
       "        [ 5.8,  2.8,  5.1,  2.4],\n",
       "        [ 6.4,  3.2,  5.3,  2.3],\n",
       "        [ 6.5,  3. ,  5.5,  1.8],\n",
       "        [ 7.7,  3.8,  6.7,  2.2],\n",
       "        [ 7.7,  2.6,  6.9,  2.3],\n",
       "        [ 6. ,  2.2,  5. ,  1.5],\n",
       "        [ 6.9,  3.2,  5.7,  2.3],\n",
       "        [ 5.6,  2.8,  4.9,  2. ],\n",
       "        [ 7.7,  2.8,  6.7,  2. ],\n",
       "        [ 6.3,  2.7,  4.9,  1.8],\n",
       "        [ 6.7,  3.3,  5.7,  2.1],\n",
       "        [ 7.2,  3.2,  6. ,  1.8],\n",
       "        [ 6.2,  2.8,  4.8,  1.8],\n",
       "        [ 6.1,  3. ,  4.9,  1.8],\n",
       "        [ 6.4,  2.8,  5.6,  2.1],\n",
       "        [ 7.2,  3. ,  5.8,  1.6],\n",
       "        [ 7.4,  2.8,  6.1,  1.9],\n",
       "        [ 7.9,  3.8,  6.4,  2. ],\n",
       "        [ 6.4,  2.8,  5.6,  2.2],\n",
       "        [ 6.3,  2.8,  5.1,  1.5],\n",
       "        [ 6.1,  2.6,  5.6,  1.4],\n",
       "        [ 7.7,  3. ,  6.1,  2.3],\n",
       "        [ 6.3,  3.4,  5.6,  2.4],\n",
       "        [ 6.4,  3.1,  5.5,  1.8],\n",
       "        [ 6. ,  3. ,  4.8,  1.8],\n",
       "        [ 6.9,  3.1,  5.4,  2.1],\n",
       "        [ 6.7,  3.1,  5.6,  2.4],\n",
       "        [ 6.9,  3.1,  5.1,  2.3],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 6.8,  3.2,  5.9,  2.3],\n",
       "        [ 6.7,  3.3,  5.7,  2.5],\n",
       "        [ 6.7,  3. ,  5.2,  2.3],\n",
       "        [ 6.3,  2.5,  5. ,  1.9],\n",
       "        [ 6.5,  3. ,  5.2,  2. ],\n",
       "        [ 6.2,  3.4,  5.4,  2.3],\n",
       "        [ 5.9,  3. ,  5.1,  1.8]]),\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], \n",
       "       dtype='<U10')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.datasets.base.Bunch"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n"
     ]
    }
   ],
   "source": [
    "print(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], \n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(iris.data))\n",
    "print(type(iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = iris.data # X uppercase since it is matrix\n",
    "y = iris.target  # y lowercase since it is vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajay/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict([3,5,4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_new = ([3,5,4,2], [5,4,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "longreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longreg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longreg.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris.data\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = iris.target\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X,y)\n",
    "\n",
    "logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg.predict(X)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X,y)\n",
    "y_pred = knn.predict(X)\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X,y)\n",
    "y_pred = knn.predict(X)\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test/split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(60, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90,)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_range = range(1, 26)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f75c5a58dd8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75c5a852b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Value of k for KNN')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986666666667\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(X, y)\n",
    "y_pred = knn.predict(X)\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajay/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict([3,5,4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], \n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
